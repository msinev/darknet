[net]
subdivisions=1
inputs=256
batch = 1
momentum=0.9
decay=0.001
max_batches = 20000
time_steps=1
learning_rate=0.1
policy=steps
steps=1000,1500
scales=.1,.1

[connected]
output=512
activation=relu

#[dropout]
#probability=.5

[connected]
output=1024
activation=relu


[connected]
output=256
activation=relu


#[dropout]
#probability=.5

[connected]
output=20
activation=linear

[softmax]
groups=1

[cost]
type=sse

